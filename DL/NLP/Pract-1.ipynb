{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "str = \"GLA is the worst university. It offers B.Tech program. They are worst.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize # for single sentence\n",
    "from nltk.tokenize import sent_tokenize # for many sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kulsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GLA is the worst university.', 'It offers B.Tech program.', 'They are worst.']\n"
     ]
    }
   ],
   "source": [
    "token1 = sent_tokenize(str)\n",
    "print(token1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GLA', 'is', 'the', 'worst', 'university', '.']\n",
      "['It', 'offers', 'B.Tech', 'program', '.']\n",
      "['They', 'are', 'worst', '.']\n",
      "[['GLA', 'is', 'the', 'worst', 'university', '.'], ['It', 'offers', 'B.Tech', 'program', '.'], ['They', 'are', 'worst', '.']]\n",
      "['GLA', 'is', 'the', 'worst', 'university', '.', 'It', 'offers', 'B.Tech', 'program', '.', 'They', 'are', 'worst', '.']\n"
     ]
    }
   ],
   "source": [
    "list = []\n",
    "list1= []\n",
    "for i in token1:\n",
    "    token2 = word_tokenize(i)\n",
    "    list1 += token2\n",
    "    list.append(token2)\n",
    "    print(token2)\n",
    "print(list)\n",
    "print(list1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stemming** - removing prefix and suffix\n",
    "\n",
    "* Plays\n",
    "* Playing\n",
    "* Played\n",
    "* does\n",
    "* redo\n",
    "* students\n",
    "* Universities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'student'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "ps.stem(\"students\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stud'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = LancasterStemmer()\n",
    "ps.stem(\"students\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ps = SnowballStemmer()\n",
    "# ps.stem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lemmatization** - Save only the root word instead of other forms\n",
    "\n",
    "* good\n",
    "* better\n",
    "* best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kulsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma1 = WordNetLemmatizer()\n",
    "lemma1.lemmatize(\"better\", pos=\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**POS Tagging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\kulsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('GLA', 'NNP'), ('is', 'VBZ'), ('the', 'DT'), ('worst', 'JJS'), ('university', 'NN'), ('.', '.'), ('It', 'PRP'), ('offers', 'VBZ'), ('B.Tech', 'NNP'), ('program', 'NN'), ('.', '.'), ('They', 'PRP'), ('are', 'VBP'), ('worst', 'RB'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "tag1 = nltk.pos_tag(list1)\n",
    "print(tag1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Saumya', 'NNP'), ('is', 'VBZ'), ('the', 'DT'), ('best', 'JJS')]\n"
     ]
    }
   ],
   "source": [
    "str = \"Saumya is the best\"\n",
    "ans = word_tokenize(str)\n",
    "print(nltk.pos_tag(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('GLA', 'NNP'), ('warden', 'NN'), ('are', 'VBP'), ('dumb', 'JJ'), ('asses', 'NNS')]\n"
     ]
    }
   ],
   "source": [
    "str = \"GLA warden are dumb asses\"\n",
    "ans = word_tokenize(str)\n",
    "print(nltk.pos_tag(ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stopwords** \n",
    "\n",
    "* the\n",
    "* a\n",
    "* an\n",
    "* for\n",
    "* of\n",
    "* is\n",
    "* are\n",
    "* am\n",
    "* this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kulsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "stop1 = stopwords.words('english')\n",
    "print(stop1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GLA', 'worst', 'university', '.', 'It', 'offers', 'B.Tech', 'program', '.', 'They', 'worst', '.']\n"
     ]
    }
   ],
   "source": [
    "for i in stop1:\n",
    "    if i in list1:\n",
    "        list1.remove(i)\n",
    "print(list1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word file import and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = Document('./Test.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "par = [p.text for p in doc.paragraphs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "par = ''.join(par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Deep learning has recently driven tremendous progress in a wide array of applications, ranging from realistic image generation and impressive retrieval systems to language models that can hold human-like conversations. While this progress is very exciting, the widespread use of deep neural network models requires caution: as guided by Google’s AI Principles, we seek to develop AI technologies responsibly by understanding and mitigating potential risks, such as the propagation and amplification of unfair biases and protecting user privacy.Fully erasing the influence of the data requested to be deleted is challenging since, aside from simply deleting it from databases where it’s stored, it also requires erasing the influence of that data on other artifacts such as trained machine learning models. Moreover, recent research [1, 2] has shown that in some cases it may be possible to infer with high accuracy whether an example was used to train a machine learning model using membership inference attacks (MIAs). This can raise privacy concerns, as it implies that even if an individual's data is deleted from a database, it may still be possible to infer whether that individual's data was used to train a model.\""
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_token = sent_tokenize(par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Deep learning has recently driven tremendous progress in a wide array of applications, ranging from realistic image generation and impressive retrieval systems to language models that can hold human-like conversations.',\n",
       " 'While this progress is very exciting, the widespread use of deep neural network models requires caution: as guided by Google’s AI Principles, we seek to develop AI technologies responsibly by understanding and mitigating potential risks, such as the propagation and amplification of unfair biases and protecting user privacy.Fully erasing the influence of the data requested to be deleted is challenging since, aside from simply deleting it from databases where it’s stored, it also requires erasing the influence of that data on other artifacts such as trained machine learning models.',\n",
       " 'Moreover, recent research [1, 2] has shown that in some cases it may be possible to infer with high accuracy whether an example was used to train a machine learning model using membership inference attacks (MIAs).',\n",
       " \"This can raise privacy concerns, as it implies that even if an individual's data is deleted from a database, it may still be possible to infer whether that individual's data was used to train a model.\"]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Deep', 'learning', 'has', 'recently', 'driven', 'tremendous', 'progress', 'in', 'a', 'wide', 'array', 'of', 'applications', ',', 'ranging', 'from', 'realistic', 'image', 'generation', 'and', 'impressive', 'retrieval', 'systems', 'to', 'language', 'models', 'that', 'can', 'hold', 'human-like', 'conversations', '.', 'While', 'this', 'progress', 'is', 'very', 'exciting', ',', 'the', 'widespread', 'use', 'of', 'deep', 'neural', 'network', 'models', 'requires', 'caution', ':', 'as', 'guided', 'by', 'Google', '’', 's', 'AI', 'Principles', ',', 'we', 'seek', 'to', 'develop', 'AI', 'technologies', 'responsibly', 'by', 'understanding', 'and', 'mitigating', 'potential', 'risks', ',', 'such', 'as', 'the', 'propagation', 'and', 'amplification', 'of', 'unfair', 'biases', 'and', 'protecting', 'user', 'privacy.Fully', 'erasing', 'the', 'influence', 'of', 'the', 'data', 'requested', 'to', 'be', 'deleted', 'is', 'challenging', 'since', ',', 'aside', 'from', 'simply', 'deleting', 'it', 'from', 'databases', 'where', 'it', '’', 's', 'stored', ',', 'it', 'also', 'requires', 'erasing', 'the', 'influence', 'of', 'that', 'data', 'on', 'other', 'artifacts', 'such', 'as', 'trained', 'machine', 'learning', 'models', '.', 'Moreover', ',', 'recent', 'research', '[', '1', ',', '2', ']', 'has', 'shown', 'that', 'in', 'some', 'cases', 'it', 'may', 'be', 'possible', 'to', 'infer', 'with', 'high', 'accuracy', 'whether', 'an', 'example', 'was', 'used', 'to', 'train', 'a', 'machine', 'learning', 'model', 'using', 'membership', 'inference', 'attacks', '(', 'MIAs', ')', '.', 'This', 'can', 'raise', 'privacy', 'concerns', ',', 'as', 'it', 'implies', 'that', 'even', 'if', 'an', 'individual', \"'s\", 'data', 'is', 'deleted', 'from', 'a', 'database', ',', 'it', 'may', 'still', 'be', 'possible', 'to', 'infer', 'whether', 'that', 'individual', \"'s\", 'data', 'was', 'used', 'to', 'train', 'a', 'model', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens = []\n",
    "for i in sent_token:\n",
    "    word_token = word_tokenize(i)\n",
    "    tokens += word_token\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Deep', 'learning', 'has', 'recently', 'driven', 'tremendous', 'progress', 'in', 'a', 'wide', 'array', 'of', 'applications', ',', 'ranging', 'from', 'realistic', 'image', 'generation', 'and', 'impressive', 'retrieval', 'systems', 'to', 'language', 'models', 'that', 'can', 'hold', 'human-like', 'conversations', '.', 'While', 'this', 'progress', 'is', 'very', 'exciting', ',', 'the', 'widespread', 'use', 'of', 'deep', 'neural', 'network', 'models', 'requires', 'caution', ':', 'as', 'guided', 'by', 'Google', '’', 's', 'AI', 'Principles', ',', 'we', 'seek', 'to', 'develop', 'AI', 'technologies', 'responsibly', 'by', 'understanding', 'and', 'mitigating', 'potential', 'risks', ',', 'such', 'as', 'the', 'propagation', 'and', 'amplification', 'of', 'unfair', 'biases', 'and', 'protecting', 'user', 'privacy.Fully', 'erasing', 'the', 'influence', 'of', 'the', 'data', 'requested', 'to', 'be', 'deleted', 'is', 'challenging', 'since', ',', 'aside', 'from', 'simply', 'deleting', 'it', 'from', 'databases', 'where', 'it', '’', 's', 'stored', ',', 'it', 'also', 'requires', 'erasing', 'the', 'influence', 'of', 'that', 'data', 'on', 'other', 'artifacts', 'such', 'as', 'trained', 'machine', 'learning', 'models', '.', 'Moreover', ',', 'recent', 'research', '[', '1', ',', '2', ']', 'has', 'shown', 'that', 'in', 'some', 'cases', 'it', 'may', 'be', 'possible', 'to', 'infer', 'with', 'high', 'accuracy', 'whether', 'an', 'example', 'was', 'used', 'to', 'train', 'a', 'machine', 'learning', 'model', 'using', 'membership', 'inference', 'attacks', '(', 'MIAs', ')', '.', 'This', 'can', 'raise', 'privacy', 'concerns', ',', 'as', 'it', 'implies', 'that', 'even', 'if', 'an', 'individual', \"'s\", 'data', 'is', 'deleted', 'from', 'a', 'database', ',', 'it', 'may', 'still', 'be', 'possible', 'to', 'infer', 'whether', 'that', 'individual', \"'s\", 'data', 'was', 'used', 'to', 'train', 'a', 'model', '.']\n"
     ]
    }
   ],
   "source": [
    "for i in tokens:\n",
    "    ps = PorterStemmer()\n",
    "    ps.stem(i)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NNP',\n",
       " 'NN',\n",
       " 'VBZ',\n",
       " 'RB',\n",
       " 'VBN',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NNS',\n",
       " ',',\n",
       " 'VBG',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'CC',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'NNS',\n",
       " 'TO',\n",
       " 'NN',\n",
       " 'NNS',\n",
       " 'WDT',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'JJ',\n",
       " 'NNS',\n",
       " '.',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'VBZ',\n",
       " 'RB',\n",
       " 'JJ',\n",
       " ',',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'NNS',\n",
       " 'VBZ',\n",
       " 'NN',\n",
       " ':',\n",
       " 'IN',\n",
       " 'VBN',\n",
       " 'IN',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'NN',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " ',',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'NNP',\n",
       " 'NNS',\n",
       " 'RB',\n",
       " 'IN',\n",
       " 'VBG',\n",
       " 'CC',\n",
       " 'VBG',\n",
       " 'JJ',\n",
       " 'NNS',\n",
       " ',',\n",
       " 'JJ',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'CC',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'NNS',\n",
       " 'CC',\n",
       " 'VBG',\n",
       " 'RBR',\n",
       " 'RB',\n",
       " 'VBG',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNS',\n",
       " 'VBD',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'VBN',\n",
       " 'VBZ',\n",
       " 'VBG',\n",
       " 'IN',\n",
       " ',',\n",
       " 'RB',\n",
       " 'IN',\n",
       " 'RB',\n",
       " 'VBG',\n",
       " 'PRP',\n",
       " 'IN',\n",
       " 'VBZ',\n",
       " 'WRB',\n",
       " 'PRP',\n",
       " 'VBZ',\n",
       " 'JJ',\n",
       " 'VBN',\n",
       " ',',\n",
       " 'PRP',\n",
       " 'RB',\n",
       " 'VBZ',\n",
       " 'VBG',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'NNS',\n",
       " 'JJ',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'NNS',\n",
       " '.',\n",
       " 'RB',\n",
       " ',',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'VBZ',\n",
       " 'CD',\n",
       " ',',\n",
       " 'CD',\n",
       " 'NN',\n",
       " 'VBZ',\n",
       " 'VBN',\n",
       " 'IN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNS',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'JJ',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'VBD',\n",
       " 'VBN',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'VBG',\n",
       " 'NN',\n",
       " 'VBG',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'NNS',\n",
       " '(',\n",
       " 'NNP',\n",
       " ')',\n",
       " '.',\n",
       " 'DT',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'NN',\n",
       " 'NNS',\n",
       " ',',\n",
       " 'IN',\n",
       " 'PRP',\n",
       " 'VBZ',\n",
       " 'IN',\n",
       " 'RB',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'POS',\n",
       " 'NN',\n",
       " 'VBZ',\n",
       " 'VBN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " ',',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'RB',\n",
       " 'VB',\n",
       " 'JJ',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'POS',\n",
       " 'NN',\n",
       " 'VBD',\n",
       " 'VBN',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'DT',\n",
       " 'NN',\n",
       " '.']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = []\n",
    "for i in nltk.pos_tag(tokens):\n",
    "    tags.append(i[1])\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ps = PorterStemmer()\n",
    "# j = 0\n",
    "# for i in tokens:\n",
    "#     tokens[j] = lemma1.lemmatize(i, pos=tags[j])\n",
    "#     j += 1\n",
    "# print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216\n",
      "188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Deep',\n",
       " 'learning',\n",
       " 'recently',\n",
       " 'driven',\n",
       " 'tremendous',\n",
       " 'progress',\n",
       " 'wide',\n",
       " 'array',\n",
       " 'applications',\n",
       " ',',\n",
       " 'ranging',\n",
       " 'realistic',\n",
       " 'image',\n",
       " 'generation',\n",
       " 'impressive',\n",
       " 'retrieval',\n",
       " 'systems',\n",
       " 'language',\n",
       " 'models',\n",
       " 'hold',\n",
       " 'human-like',\n",
       " 'conversations',\n",
       " '.',\n",
       " 'While',\n",
       " 'progress',\n",
       " 'exciting',\n",
       " ',',\n",
       " 'widespread',\n",
       " 'use',\n",
       " 'of',\n",
       " 'deep',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'models',\n",
       " 'requires',\n",
       " 'caution',\n",
       " ':',\n",
       " 'guided',\n",
       " 'Google',\n",
       " '’',\n",
       " 'AI',\n",
       " 'Principles',\n",
       " ',',\n",
       " 'seek',\n",
       " 'to',\n",
       " 'develop',\n",
       " 'AI',\n",
       " 'technologies',\n",
       " 'responsibly',\n",
       " 'by',\n",
       " 'understanding',\n",
       " 'and',\n",
       " 'mitigating',\n",
       " 'potential',\n",
       " 'risks',\n",
       " ',',\n",
       " 'as',\n",
       " 'the',\n",
       " 'propagation',\n",
       " 'and',\n",
       " 'amplification',\n",
       " 'of',\n",
       " 'unfair',\n",
       " 'biases',\n",
       " 'and',\n",
       " 'protecting',\n",
       " 'user',\n",
       " 'privacy.Fully',\n",
       " 'erasing',\n",
       " 'the',\n",
       " 'influence',\n",
       " 'of',\n",
       " 'the',\n",
       " 'data',\n",
       " 'requested',\n",
       " 'to',\n",
       " 'deleted',\n",
       " 'is',\n",
       " 'challenging',\n",
       " 'since',\n",
       " ',',\n",
       " 'aside',\n",
       " 'from',\n",
       " 'simply',\n",
       " 'deleting',\n",
       " 'from',\n",
       " 'databases',\n",
       " 'it',\n",
       " '’',\n",
       " 's',\n",
       " 'stored',\n",
       " ',',\n",
       " 'it',\n",
       " 'also',\n",
       " 'requires',\n",
       " 'erasing',\n",
       " 'the',\n",
       " 'influence',\n",
       " 'of',\n",
       " 'that',\n",
       " 'data',\n",
       " 'artifacts',\n",
       " 'such',\n",
       " 'as',\n",
       " 'trained',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'models',\n",
       " '.',\n",
       " 'Moreover',\n",
       " ',',\n",
       " 'recent',\n",
       " 'research',\n",
       " '[',\n",
       " '1',\n",
       " ',',\n",
       " '2',\n",
       " ']',\n",
       " 'has',\n",
       " 'shown',\n",
       " 'that',\n",
       " 'in',\n",
       " 'cases',\n",
       " 'it',\n",
       " 'may',\n",
       " 'be',\n",
       " 'possible',\n",
       " 'to',\n",
       " 'infer',\n",
       " 'high',\n",
       " 'accuracy',\n",
       " 'whether',\n",
       " 'example',\n",
       " 'used',\n",
       " 'to',\n",
       " 'train',\n",
       " 'a',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'model',\n",
       " 'using',\n",
       " 'membership',\n",
       " 'inference',\n",
       " 'attacks',\n",
       " '(',\n",
       " 'MIAs',\n",
       " ')',\n",
       " '.',\n",
       " 'This',\n",
       " 'can',\n",
       " 'raise',\n",
       " 'privacy',\n",
       " 'concerns',\n",
       " ',',\n",
       " 'as',\n",
       " 'it',\n",
       " 'implies',\n",
       " 'that',\n",
       " 'even',\n",
       " 'an',\n",
       " 'individual',\n",
       " \"'s\",\n",
       " 'data',\n",
       " 'is',\n",
       " 'deleted',\n",
       " 'from',\n",
       " 'a',\n",
       " 'database',\n",
       " ',',\n",
       " 'it',\n",
       " 'may',\n",
       " 'still',\n",
       " 'be',\n",
       " 'possible',\n",
       " 'to',\n",
       " 'infer',\n",
       " 'whether',\n",
       " 'that',\n",
       " 'individual',\n",
       " \"'s\",\n",
       " 'data',\n",
       " 'was',\n",
       " 'used',\n",
       " 'to',\n",
       " 'train',\n",
       " 'a',\n",
       " 'model',\n",
       " '.']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(tokens))\n",
    "for i in stop1:\n",
    "    if i in tokens:\n",
    "        tokens.remove(i)\n",
    "print(len(tokens))\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_doc = Document()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = new_doc.add_paragraph()\n",
    "for i in tokens:\n",
    "    para.add_run(i + '\\n')\n",
    "\n",
    "new_doc.save('ans.docx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-intel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
