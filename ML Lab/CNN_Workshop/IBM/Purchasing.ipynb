{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.read_csv('dataset/online_shoppers_intention.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dt.iloc[:, :-1]\n",
    "y = dt.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "X_train.reset_index(inplace = True)\n",
    "X_test.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['Administrative', 'Informational', 'ProductRelated'], axis = 1)\n",
    "X_test = X_test.drop(['Administrative', 'Informational', 'ProductRelated'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(['OperatingSystems', 'Region', 'TrafficType'], axis = 1, inplace = True)\n",
    "X_test.drop(['OperatingSystems', 'Region', 'TrafficType'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kulsh\\AppData\\Local\\Temp\\ipykernel_24628\\2499845469.py:2: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X_train.loc[:, 'Month'] = labelEncoder.fit_transform(X_train.loc[:, 'Month'])\n",
      "C:\\Users\\kulsh\\AppData\\Local\\Temp\\ipykernel_24628\\2499845469.py:3: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X_test.loc[:, 'Month'] = labelEncoder.transform(X_test.loc[:, 'Month'])\n",
      "C:\\Users\\kulsh\\AppData\\Local\\Temp\\ipykernel_24628\\2499845469.py:4: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X_train.loc[:, 'VisitorType'] = labelEncoder.fit_transform(X_train.loc[:, 'VisitorType'])\n",
      "C:\\Users\\kulsh\\AppData\\Local\\Temp\\ipykernel_24628\\2499845469.py:5: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X_test.loc[:, 'VisitorType'] = labelEncoder.transform(X_test.loc[:, 'VisitorType'])\n"
     ]
    }
   ],
   "source": [
    "labelEncoder = LabelEncoder()\n",
    "X_train.loc[:, 'Month'] = labelEncoder.fit_transform(X_train.loc[:, 'Month'])\n",
    "X_test.loc[:, 'Month'] = labelEncoder.transform(X_test.loc[:, 'Month'])\n",
    "X_train.loc[:, 'VisitorType'] = labelEncoder.fit_transform(X_train.loc[:, 'VisitorType'])\n",
    "X_test.loc[:, 'VisitorType'] = labelEncoder.transform(X_test.loc[:, 'VisitorType'])\n",
    "X_train.loc[:, 'Weekend'] = labelEncoder.fit_transform(X_train.loc[:, 'Weekend'])\n",
    "X_test.loc[:, 'Weekend'] = labelEncoder.transform(X_test.loc[:, 'Weekend'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehotencoder = OneHotEncoder(categories = 'auto', drop = 'first')\n",
    "train_cat_features = onehotencoder.fit_transform(X_train.loc[:, ['Month', 'Browser', 'VisitorType']]).toarray()\n",
    "train_cat_features = pd.DataFrame(train_cat_features)\n",
    "test_cat_features = onehotencoder.transform(X_test.loc[:, ['Month', 'Browser', 'VisitorType']]).toarray()\n",
    "test_cat_features = pd.DataFrame(test_cat_features)\n",
    "\n",
    "X_train.drop(['Month', 'Browser', 'VisitorType'], axis = 1, inplace = True)\n",
    "X_train = X_train.join(train_cat_features)\n",
    "X_test.drop(['Month', 'Browser', 'VisitorType'], axis = 1, inplace = True)\n",
    "X_test = X_test.join(test_cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               4224      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,785\n",
      "Trainable params: 86,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(units = 128, activation = 'relu', input_dim = 32))\n",
    "classifier.add(Dropout(rate = 0.6))\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dropout(rate = 0.6))\n",
    "classifier.add(Dense(units = 256, activation = 'relu'))\n",
    "classifier.add(Dropout(rate = 0.6))\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dropout(rate = 0.4))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "278/278 [==============================] - 3s 5ms/step - loss: 86.3254 - accuracy: 0.7230 - val_loss: 1.3091 - val_accuracy: 0.8470\n",
      "Epoch 2/50\n",
      "278/278 [==============================] - 1s 4ms/step - loss: 15.5683 - accuracy: 0.7196 - val_loss: 0.6225 - val_accuracy: 0.8480\n",
      "Epoch 3/50\n",
      "278/278 [==============================] - 1s 4ms/step - loss: 5.4878 - accuracy: 0.7319 - val_loss: 0.6035 - val_accuracy: 0.8470\n",
      "Epoch 4/50\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 2.6600 - accuracy: 0.7514 - val_loss: 0.5459 - val_accuracy: 0.8480\n",
      "Epoch 5/50\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 1.6148 - accuracy: 0.7812 - val_loss: 0.4935 - val_accuracy: 0.8480\n",
      "Epoch 6/50\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 1.0792 - accuracy: 0.8009 - val_loss: 0.4549 - val_accuracy: 0.8480\n",
      "Epoch 7/50\n",
      "278/278 [==============================] - 1s 4ms/step - loss: 0.8263 - accuracy: 0.8146 - val_loss: 0.4339 - val_accuracy: 0.8480\n",
      "Epoch 8/50\n",
      "278/278 [==============================] - 1s 4ms/step - loss: 0.6706 - accuracy: 0.8270 - val_loss: 0.4280 - val_accuracy: 0.8480\n",
      "Epoch 9/50\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.6087 - accuracy: 0.8316 - val_loss: 0.4267 - val_accuracy: 0.8480\n",
      "Epoch 10/50\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.5964 - accuracy: 0.8379 - val_loss: 0.4269 - val_accuracy: 0.8480\n",
      "Epoch 11/50\n",
      "278/278 [==============================] - 1s 4ms/step - loss: 0.5140 - accuracy: 0.8387 - val_loss: 0.4267 - val_accuracy: 0.8480\n",
      "Epoch 12/50\n",
      "278/278 [==============================] - 1s 4ms/step - loss: 0.4901 - accuracy: 0.8400 - val_loss: 0.4267 - val_accuracy: 0.8480\n",
      "Epoch 13/50\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.4890 - accuracy: 0.8390 - val_loss: 0.4266 - val_accuracy: 0.8480\n",
      "Epoch 14/50\n",
      "278/278 [==============================] - 1s 4ms/step - loss: 0.4702 - accuracy: 0.8413 - val_loss: 0.4263 - val_accuracy: 0.8480\n",
      "Epoch 15/50\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.4752 - accuracy: 0.8420 - val_loss: 0.4262 - val_accuracy: 0.8480\n",
      "Epoch 16/50\n",
      "278/278 [==============================] - 1s 4ms/step - loss: 0.4618 - accuracy: 0.8434 - val_loss: 0.4262 - val_accuracy: 0.8480\n",
      "Epoch 17/50\n",
      "278/278 [==============================] - 1s 4ms/step - loss: 0.4530 - accuracy: 0.8445 - val_loss: 0.4262 - val_accuracy: 0.8480\n",
      "Epoch 18/50\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.4473 - accuracy: 0.8448 - val_loss: 0.4265 - val_accuracy: 0.8480\n",
      "Epoch 19/50\n",
      "278/278 [==============================] - 1s 4ms/step - loss: 0.4440 - accuracy: 0.8457 - val_loss: 0.4262 - val_accuracy: 0.8480\n",
      "Epoch 20/50\n",
      "278/278 [==============================] - 1s 4ms/step - loss: 0.4408 - accuracy: 0.8462 - val_loss: 0.4262 - val_accuracy: 0.8480\n",
      "Epoch 21/50\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.4379 - accuracy: 0.8474 - val_loss: 0.4262 - val_accuracy: 0.8480\n",
      "Epoch 22/50\n",
      "278/278 [==============================] - 1s 4ms/step - loss: 0.4396 - accuracy: 0.8467 - val_loss: 0.4263 - val_accuracy: 0.8480\n",
      "Epoch 23/50\n",
      "278/278 [==============================] - 1s 4ms/step - loss: 0.4327 - accuracy: 0.8474 - val_loss: 0.4262 - val_accuracy: 0.8480\n",
      "Epoch 24/50\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.4346 - accuracy: 0.8463 - val_loss: 0.4261 - val_accuracy: 0.8480\n",
      "Epoch 25/50\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.4307 - accuracy: 0.8470 - val_loss: 0.4262 - val_accuracy: 0.8480\n",
      "Epoch 26/50\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.4374 - accuracy: 0.8467 - val_loss: 0.4263 - val_accuracy: 0.8480\n",
      "Epoch 27/50\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.4315 - accuracy: 0.8478 - val_loss: 0.4262 - val_accuracy: 0.8480\n",
      "Epoch 28/50\n",
      "278/278 [==============================] - 2s 6ms/step - loss: 0.4286 - accuracy: 0.8480 - val_loss: 0.4262 - val_accuracy: 0.8480\n",
      "Epoch 29/50\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.4317 - accuracy: 0.8477 - val_loss: 0.4263 - val_accuracy: 0.8480\n",
      "Epoch 30/50\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.4303 - accuracy: 0.8471 - val_loss: 0.4262 - val_accuracy: 0.8480\n",
      "Epoch 31/50\n",
      "278/278 [==============================] - 1s 4ms/step - loss: 0.4311 - accuracy: 0.8476 - val_loss: 0.4262 - val_accuracy: 0.8480\n",
      "Epoch 32/50\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.4299 - accuracy: 0.8478 - val_loss: 0.4262 - val_accuracy: 0.8480\n",
      "Epoch 33/50\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.4297 - accuracy: 0.8470 - val_loss: 0.4262 - val_accuracy: 0.8480\n",
      "Epoch 34/50\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.4291 - accuracy: 0.8480 - val_loss: 0.4262 - val_accuracy: 0.8480\n",
      "Epoch 35/50\n",
      "278/278 [==============================] - 1s 4ms/step - loss: 0.4275 - accuracy: 0.8478 - val_loss: 0.4262 - val_accuracy: 0.8480\n",
      "Epoch 36/50\n",
      "278/278 [==============================] - 1s 4ms/step - loss: 0.4321 - accuracy: 0.8477 - val_loss: 0.4262 - val_accuracy: 0.8480\n",
      "Epoch 37/50\n",
      "278/278 [==============================] - 1s 4ms/step - loss: 0.4289 - accuracy: 0.8477 - val_loss: 0.4262 - val_accuracy: 0.8480\n",
      "Epoch 38/50\n",
      "278/278 [==============================] - 1s 4ms/step - loss: 0.4294 - accuracy: 0.8480 - val_loss: 0.4262 - val_accuracy: 0.8480\n",
      "Epoch 39/50\n",
      "278/278 [==============================] - 1s 4ms/step - loss: 0.4286 - accuracy: 0.8476 - val_loss: 0.4263 - val_accuracy: 0.8480\n",
      "Epoch 40/50\n",
      "278/278 [==============================] - 1s 4ms/step - loss: 0.4300 - accuracy: 0.8478 - val_loss: 0.4262 - val_accuracy: 0.8480\n",
      "Epoch 41/50\n",
      "278/278 [==============================] - 1s 4ms/step - loss: 0.4280 - accuracy: 0.8480 - val_loss: 0.4263 - val_accuracy: 0.8480\n",
      "Epoch 42/50\n",
      "278/278 [==============================] - 1s 4ms/step - loss: 0.4268 - accuracy: 0.8481 - val_loss: 0.4264 - val_accuracy: 0.8480\n",
      "Epoch 43/50\n",
      "278/278 [==============================] - 1s 4ms/step - loss: 0.4286 - accuracy: 0.8479 - val_loss: 0.4262 - val_accuracy: 0.8480\n",
      "Epoch 44/50\n",
      "278/278 [==============================] - 1s 4ms/step - loss: 0.4269 - accuracy: 0.8481 - val_loss: 0.4263 - val_accuracy: 0.8480\n",
      "Epoch 45/50\n",
      "278/278 [==============================] - 1s 4ms/step - loss: 0.4275 - accuracy: 0.8480 - val_loss: 0.4262 - val_accuracy: 0.8480\n",
      "Epoch 46/50\n",
      "278/278 [==============================] - 1s 4ms/step - loss: 0.4271 - accuracy: 0.8480 - val_loss: 0.4262 - val_accuracy: 0.8480\n",
      "Epoch 47/50\n",
      "278/278 [==============================] - 1s 4ms/step - loss: 0.4261 - accuracy: 0.8480 - val_loss: 0.4262 - val_accuracy: 0.8480\n",
      "Epoch 48/50\n",
      "278/278 [==============================] - 1s 4ms/step - loss: 0.4261 - accuracy: 0.8483 - val_loss: 0.4262 - val_accuracy: 0.8480\n",
      "Epoch 49/50\n",
      "278/278 [==============================] - 1s 4ms/step - loss: 0.4273 - accuracy: 0.8481 - val_loss: 0.4264 - val_accuracy: 0.8480\n",
      "Epoch 50/50\n",
      "278/278 [==============================] - 1s 4ms/step - loss: 0.4277 - accuracy: 0.8479 - val_loss: 0.4264 - val_accuracy: 0.8480\n"
     ]
    }
   ],
   "source": [
    "history = classifier.fit(X_train, y_train, epochs = 50, shuffle = False, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 0s 2ms/step\n",
      "Confusion matrix:\n",
      "[[2055    0]\n",
      " [ 411    0]]\n",
      "Accuracy: 83.33%\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = y_pred > 0.5\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy_score(y_test, y_pred)*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1ed739916f056cbaa1c1d07d49b59abad810f48beee2c23ab8674585a1239e62"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
